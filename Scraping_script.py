# -*- coding: utf-8 -*-
"""Scraping Script.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fGg3NWyrNampNcZspL7uFfJS8JuVRmAI

# Scraping Script

## Import packages
"""

import pandas as pd
import numpy as np
#from selenium import webdriver
#from selenium.webdriver.common.keys import Keys
#from selenium.webdriver.support.ui import Select
#from selenium.webdriver.chrome.service import Service
import requests
from bs4 import BeautifulSoup
import time
import re
import string

from datetime import date

import datetime

"""## Specify Path"""

url = 'http://www.olympedia.org/results/19000437'



"""## Get 2021 results"""

dfs = pd.read_html('http://www.olympedia.org/results/19000437',encoding='utf8')

#Get the right dataframe
dat_2021 = dfs[1]
#Get rid of no-finishers
dat_2021_clean = dat_2021[dat_2021.Pos != "AC"][['Athlete', 'NOC', 'Time']]
#get time in a consistent format
hours = dat_2021_clean.Time.apply(lambda x: int(x[0]))
minutes = dat_2021_clean.Time.apply(lambda x: int(x[2:4]))
seconds = dat_2021_clean.Time.apply(lambda x: int(x[5:7]))
dat_2021_clean.Time = hours * 3600 + minutes * 60 + seconds
print(dat_2021_clean)

"""## Get 2021 athlete data"""

page = requests.get(url)
soup = BeautifulSoup(page.text, 'html.parser')



#Get athlete id's so that I can parse through the profile pages
athlete_id = []
i = 0
for a in soup.find_all('a', href=True):
    if a['href'][1:9] == 'athletes':
        athlete_id.append(a['href'][9:])
        i = i + 1

print(athlete_id)
athlete_id_clean = list(set(athlete_id[4:]))
print(athlete_id_clean)





#parse through athlete profiles
ath_url = 'http://www.olympedia.org/athletes'
ath_list = []
for ath in athlete_id_clean:
    ath_list.append(pd.read_html(ath_url + ath, encoding='utf8'))



#Get athlete attribute table from the athlete profiles
ath_attr = []
for attr in ath_list:
    for tables in attr:
        if tables.iloc[0,0] == 'Type':
            tables.columns = ['attr', 'val']
            column_names = tables.attr.to_numpy()
            value_names = tables.val.to_numpy()
            new_table = pd.DataFrame(value_names.reshape(-1, len(value_names)), columns = column_names)
            ath_attr.append(new_table)


print(ath_attr)

#clean up the data
attr_table = pd.concat(ath_attr).reset_index()
attr_table = attr_table[['Sex', 'Used name', 'Born', 'NOC', 'Measurements']]
#Get birth elements
pattern = '\d+'
attr_table['day'] = attr_table.Born.apply(lambda x: int(re.findall(pattern, x)[0]))
attr_table['year'] = attr_table.Born.apply(lambda x: int(re.findall(pattern, x)[1]))
pattern2 = '\D+(?=\s)'
attr_table['month'] = attr_table.Born.apply(lambda x: re.findall(pattern2, x)[0])
attr_table['age'] = 2021 - attr_table.year
attr_table = attr_table.drop('Born', axis=1)
#Get the used name in correct format
attr_table['Used name'] = attr_table['Used name'].apply(lambda x: x.replace('â€¢', ' '))
#Get height and weight in cm and kg
attr_table['height'] = np.nan
attr_table['weight'] = np.nan
pattern = ' cm'
pattern = '\d+'
for i in range(len(attr_table)):
    if attr_table.Measurements.notna()[i]:
        height_possible = attr_table.Measurements[i].split(' cm')
        if 'k' in attr_table.Measurements[i]:
            weight_possible = attr_table.Measurements[i]
            weight_possible = weight_possible[-5:weight_possible.index("k")]
            attr_table.weight[i] = weight_possible
        if len(height_possible) > 1:
            attr_table.height[i] = height_possible[0]  
attr_table.drop(['Measurements', 'day', 'year', 'month'], inplace = True, axis = 1)
print(attr_table)

#write to csv
dat_2021_clean.to_csv('2021_results.csv', index = False)
attr_table.to_csv('runner_attributes_2021.csv', index = False)

"""#Get GDP"""

gdp = pd.read_csv("https://storage.googleapis.com/kagglesdsdata/datasets/1239930/2068732/gdp_csv.csv?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20211201%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20211201T225705Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=5dcdd0bc0de18021bde94600860592795e2d0d3db5dee6acab202d993d060f57971cf70c29ec8c28d36b4a7a9bd1c1ca342460ac8adde9441795d3eac2069a2f3a7536d3ddad431303a9fced5a088d69e28460d965a2cbfbfed4a90f353e1d6128b81b45c680f3b7bd74d639f310690ffeaa5c0fdd35dd9489e31c27c1cad2fc9cdb6c977d8433884299608fb5921192a4d25531e50be8f177450067e9104356ae71392e47d7c324bb7ce9f85f65cabd9f2b30d7ada6fcc59b3186774f011c8e746ca1517139c8a5b07d3c5e36b783912901187c986adba0bd490e06323ec521b16a8889f83a32e326608778c52b17f701e50f89d26236147ee1cd1db7dc9884")
gdp.rename(columns={"Country Code": "Country"}, inplace= True)
gdp.drop(columns= ['Country Name'], inplace= True)

"""#Get marathon attributes and times"""

def age(birthdate):
    today = date.today()
    one_or_zero = ((today.month, today.day) < (birthdate.month, birthdate.day))
    year_difference = today.year - birthdate.year
    age = year_difference - one_or_zero
    return age

def year(date):
  return date.year  

def seconds(date):
  return date.total_seconds()

Mara_attr_times = pd.read_csv('running_times.csv')
Mara_attr_times = Mara_attr_times[Mara_attr_times['Event'] == 'Marathon']
Mara_attr_times = Mara_attr_times[Mara_attr_times['Gender'] == 'Men']

# Find number of Marathons
Number_Marathons = Mara_attr_times.groupby("Name").count()
Number_Marathons.reset_index(inplace= True)
Number_Marathons = Number_Marathons.filter(['Name', 'Rank'])
Number_Marathons['Previous marathons'] = Number_Marathons['Rank']

#Convert to Datetime
Mara_attr_times['Date of Birth'] = pd.to_datetime(Mara_attr_times['Date of Birth'])
Mara_attr_times['Date'] = pd.to_datetime(Mara_attr_times['Date'])
Mara_attr_times['Time'] = pd.to_datetime(Mara_attr_times['Time'], format= "%H:%M:%S") - datetime.datetime(1900, 1, 1)

#Clean the data
Mara_attr_times['Year'] = Mara_attr_times['Date'].apply(year)
Mara_attr_times['Age'] = Mara_attr_times['Date of Birth'].apply(age)
Mara_attr_times['Time'] = Mara_attr_times['Time'].apply(seconds)
Mara_attr_times.drop(columns = ['Date of Birth', 'Gender', 'Event', 'Rank', 'Place', 'City'], inplace= True)

#Merge GDP and Previous Marathons
Mara_attr_times = pd.merge(Mara_attr_times, Number_Marathons, on = "Name")
Mara_attr_times = pd.merge(Mara_attr_times, gdp, on = ['Country', 'Year'], how = "left")
Mara_attr_times["GDP"] = Mara_attr_times["Value"]
Mara_attr_times.drop(columns=['Country', 'Value', 'Rank'], inplace= True)

#Last_Time = Mara_attr_times.sort_values('Year').groupby('Name').tail(1)
#Last_Time = Last_Time.filter(["Time", "Name"])
#Last_Time.rename(columns={"Time": "Latest Time"}, inplace= True)
#pd.merge(Mara_attr_times, Last_Time, on = "Name")

Athlete_events = pd.read_csv("athlete_events.csv")

Athlete_events = Athlete_events[Athlete_events["Sex"] == "M"]

Athlete_events.drop_duplicates(subset=['Name'], inplace= True)
Athlete_events = Athlete_events.filter(['Name','Weight','Height'])

Mara_attr_times = pd.merge(Mara_attr_times, Athlete_events, on = "Name", how = "left")

Mara_attr_times